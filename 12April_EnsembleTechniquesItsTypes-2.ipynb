{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc0423-908e-4334-8f99-eedacb942241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging in Machine Learning\n",
    "\n",
    "## Q1. How does bagging reduce overfitting in decision trees?\n",
    "Bagging reduces overfitting by training multiple decision trees on different bootstrap samples of the data and averaging their predictions. This process decreases the variance of the model, leading to better generalization and reduced overfitting.\n",
    "\n",
    "## Q2. What are the advantages and disadvantages of using different types of base learners in bagging?\n",
    "**Advantages:**\n",
    "- **Diverse base learners**: Capture various aspects of the data and improve ensemble performance.\n",
    "- **Flexibility**: Leverage strengths of different models.\n",
    "\n",
    "**Disadvantages:**\n",
    "- **Complexity**: Increased model complexity due to managing and combining different types of base learners.\n",
    "- **Interpretability**: Harder to interpret ensembles with diverse base learners.\n",
    "\n",
    "## Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?\n",
    "- **High-bias base learners**: Can lead to a higher bias overall, as they are less complex and might not capture the data well.\n",
    "- **High-variance base learners**: Bagging reduces variance by averaging predictions, helping to control overfitting. \n",
    "\n",
    "## Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?\n",
    "- **Classification**: Bagging combines the predictions of multiple classifiers, typically using majority voting for final classification.\n",
    "- **Regression**: Bagging combines the predictions of multiple regressors by averaging their predictions to get the final output.\n",
    "\n",
    "## Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?\n",
    "- **Role**: Larger ensembles generally provide better performance as they average out more noise and reduce variance.\n",
    "- **Number of models**: There is no fixed number; typically, an ensemble size between 50 to 100 models is used. The exact number depends on the problem and computational resources.\n",
    "\n",
    "## Q6. Can you provide an example of a real-world application of bagging in machine learning?\n",
    "An example of a real-world application of bagging is **random forests**, which use bagging with decision trees as base learners. Random forests are used in various fields, such as finance for credit scoring, healthcare for disease prediction, and image recognition for classifying objects in pictures.\n",
    "\n",
    "### Example Code for Bagging with Decision Trees in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63be9329-354a-4795-a7f2-882e3bdf3ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Initialize Bagging Classifier\n",
    "bagging_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=0)\n",
    "\n",
    "# Train model\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856b992-6e01-401c-9ed8-c52cfca51376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

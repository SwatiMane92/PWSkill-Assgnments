{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb8e60-6ffd-4cb6-9fe5-fe0c5f329ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Select only two classes for binary classification\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Q1. Mathematical formula for a linear SVM\n",
    "print(\"Mathematical formula for a linear SVM:\")\n",
    "print(\"f(x) = w * x + b\")\n",
    "print(\"where w is the weight vector, x is the feature vector, and b is the bias term.\")\n",
    "\n",
    "# Q2. Objective function of a linear SVM\n",
    "print(\"\\nObjective function of a linear SVM:\")\n",
    "print(\"minimize 1/2 * ||w||^2 + C * sum(xi)\")\n",
    "print(\"subject to y_i * (w * x_i + b) >= 1 - xi\")\n",
    "\n",
    "# Q3. The kernel trick in SVM\n",
    "print(\"\\nThe kernel trick in SVM:\")\n",
    "print(\"The kernel trick allows SVM to operate in a higher-dimensional space without explicitly computing the coordinates.\")\n",
    "print(\"It uses a kernel function (e.g., RBF, polynomial) to transform the data.\")\n",
    "\n",
    "# Q4. Role of support vectors in SVM\n",
    "print(\"\\nRole of support vectors in SVM:\")\n",
    "print(\"Support vectors are the data points closest to the hyperplane. They determine the position and orientation of the hyperplane.\")\n",
    "print(\"Example: In a 2D space, support vectors lie on the margin boundaries.\")\n",
    "\n",
    "# Q5. Illustrate Hyperplane, Marginal Plane, Soft Margin, and Hard Margin in SVM\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Create grid to plot\n",
    "xx, yy = np.meshgrid(np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1, 500),\n",
    "                     np.linspace(X[:, 1].min() - 1, X[:, 1].max() + 1, 500))\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plotting\n",
    "ax.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', marker='o', cmap=plt.cm.Paired)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, edgecolors='k', marker='s', cmap=plt.cm.Paired, alpha=0.5)\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "plt.title('Decision Boundary with Linear SVM')\n",
    "plt.show()\n",
    "\n",
    "# Q6. SVM Implementation through Iris dataset\n",
    "print(\"\\nSVM Implementation with Iris Dataset:\")\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of SVM model: {accuracy:.2f}\")\n",
    "\n",
    "# Bonus task: Implement a linear SVM classifier from scratch using Python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset again for consistency\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear SVM from scratch\n",
    "class LinearSVM:\n",
    "    def __init__(self, learning_rate=0.001, n_iter=1000, C=1.0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        self.C = C\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                condition = y_[idx] * (np.dot(x_i, self.weights) + self.bias) >= 1\n",
    "                if condition:\n",
    "                    self.weights -= self.learning_rate * (2 * 1/self.n_iter * self.weights)\n",
    "                else:\n",
    "                    self.weights -= self.learning_rate * (2 * 1/self.n_iter * self.weights - np.dot(x_i, y_[idx]))\n",
    "                    self.bias -= self.learning_rate * y_[idx]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        approx = np.dot(X, self.weights) + self.bias\n",
    "        return np.sign(approx)\n",
    "\n",
    "# Train and evaluate the custom Linear SVM\n",
    "model = LinearSVM()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_custom = model.predict(X_test)\n",
    "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "\n",
    "print(f\"Accuracy of custom Linear SVM model: {accuracy_custom:.2f}\")\n",
    "\n",
    "# Compare with scikit-learn's implementation\n",
    "print(f\"Accuracy of scikit-learn Linear SVM model: {accuracy:.2f}\")\n",
    "\n",
    "# Plot decision boundaries for the custom SVM model\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Create grid to plot\n",
    "Z_custom = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z_custom = Z_custom.reshape(xx.shape)\n",
    "\n",
    "# Plotting\n",
    "ax.contourf(xx, yy, Z_custom, alpha=0.8, cmap=plt.cm.Paired)\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', marker='o', cmap=plt.cm.Paired)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, edgecolors='k', marker='s', cmap=plt.cm.Paired, alpha=0.5)\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "plt.title('Decision Boundary with Custom Linear SVM')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

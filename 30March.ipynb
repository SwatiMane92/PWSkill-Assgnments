{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d5460-999a-4d22-94f7-bea388afea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Sample data generation for demonstration\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 10)  # 10 features\n",
    "y = np.dot(X, np.random.rand(10)) + np.random.randn(100) * 0.5\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Elastic Net Regression with cross-validation for parameter tuning\n",
    "elastic_net = ElasticNet()\n",
    "alpha_range = np.logspace(-4, 4, 100)  # Range of alpha values to test\n",
    "l1_ratio_range = np.linspace(0, 1, 11)  # Range of L1 ratio values to test\n",
    "param_grid = {'alpha': alpha_range, 'l1_ratio': l1_ratio_range}\n",
    "grid_search = GridSearchCV(elastic_net, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Q1: Elastic Net Regression Overview\n",
    "elastic_net_regression_summary = \"\"\"\n",
    "Elastic Net Regression is a linear regression technique that combines L1 (Lasso) and L2 (Ridge) regularization.\n",
    "- It adds a penalty that is a mix of both L1 and L2 penalties: λ1 * sum(|coefficients|) + λ2 * sum(coefficients^2).\n",
    "- Elastic Net is useful when there are multiple features correlated with each other.\n",
    "- It differs from Lasso (which uses only L1) and Ridge (which uses only L2) by incorporating both regularization methods.\n",
    "\"\"\"\n",
    "\n",
    "# Q2: Choosing Optimal Regularization Parameters\n",
    "optimal_parameters_summary = f\"\"\"\n",
    "The optimal values for the regularization parameters in Elastic Net Regression are chosen using GridSearchCV.\n",
    "- The two parameters to tune are:\n",
    "  1. alpha: Controls the overall strength of the regularization.\n",
    "  2. l1_ratio: Determines the mix between L1 and L2 regularization.\n",
    "- Best alpha: {best_alpha:.4f}\n",
    "- Best l1_ratio: {best_l1_ratio:.4f}\n",
    "\"\"\"\n",
    "\n",
    "# Q3: Advantages and Disadvantages of Elastic Net Regression\n",
    "elastic_net_advantages_disadvantages = \"\"\"\n",
    "Advantages:\n",
    "1. Combines benefits of both Lasso and Ridge, handling multicollinearity and feature selection.\n",
    "2. More robust than Lasso when features are highly correlated.\n",
    "\n",
    "Disadvantages:\n",
    "1. More complex to tune due to two parameters (alpha and l1_ratio).\n",
    "2. Can be less interpretable than plain Lasso or Ridge due to combined regularization.\n",
    "\"\"\"\n",
    "\n",
    "# Q4: Common Use Cases for Elastic Net Regression\n",
    "use_cases_summary = \"\"\"\n",
    "Common use cases for Elastic Net Regression include:\n",
    "1. High-dimensional datasets with many features.\n",
    "2. Scenarios where there is multicollinearity among features.\n",
    "3. Feature selection problems where some features might be redundant or irrelevant.\n",
    "\"\"\"\n",
    "\n",
    "# Q5: Interpreting Coefficients in Elastic Net Regression\n",
    "coefficient_interpretation = \"\"\"\n",
    "In Elastic Net Regression, coefficients represent the impact of each feature on the target variable.\n",
    "- The coefficients are influenced by both L1 and L2 regularization.\n",
    "- Non-zero coefficients indicate the importance of the corresponding features, with the extent of regularization affecting their magnitude.\n",
    "\"\"\"\n",
    "\n",
    "# Q6: Handling Missing Values\n",
    "missing_values_summary = \"\"\"\n",
    "Missing values should be handled before applying Elastic Net Regression. Common strategies include:\n",
    "1. Imputation (e.g., using mean, median, or a model-based approach).\n",
    "2. Removing rows or columns with missing values if feasible.\n",
    "- Elastic Net itself does not handle missing values directly.\n",
    "\"\"\"\n",
    "\n",
    "# Q7: Using Elastic Net Regression for Feature Selection\n",
    "feature_selection_summary = \"\"\"\n",
    "Elastic Net Regression performs feature selection by shrinking some coefficients towards zero.\n",
    "- Features with coefficients exactly zero are excluded from the model.\n",
    "- This combination of L1 and L2 penalties helps in selecting a subset of features and reducing model complexity.\n",
    "\"\"\"\n",
    "\n",
    "# Q8: Pickling and Unpickling a Trained Model\n",
    "with open('elastic_net_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "# Unpickling\n",
    "with open('elastic_net_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "pickle_usage_summary = \"\"\"\n",
    "Pickling a model saves it to a file, which can be loaded later without retraining.\n",
    "- This is useful for preserving the state of the model and deploying it to production environments.\n",
    "\"\"\"\n",
    "\n",
    "# Q9: Purpose of Pickling a Model\n",
    "pickling_purpose_summary = \"\"\"\n",
    "The purpose of pickling a model is to serialize the trained model into a file.\n",
    "- This allows for easy storage and retrieval.\n",
    "- It facilitates deploying the model to production or sharing it with other systems without the need for retraining.\n",
    "\"\"\"\n",
    "\n",
    "# Display results\n",
    "print(\"Q1: Elastic Net Regression Overview\")\n",
    "print(elastic_net_regression_summary)\n",
    "\n",
    "print(\"\\nQ2: Choosing Optimal Regularization Parameters\")\n",
    "print(optimal_parameters_summary)\n",
    "\n",
    "print(\"\\nQ3: Advantages and Disadvantages of Elastic Net Regression\")\n",
    "print(elastic_net_advantages_disadvantages)\n",
    "\n",
    "print(\"\\nQ4: Common Use Cases for Elastic Net Regression\")\n",
    "print(use_cases_summary)\n",
    "\n",
    "print(\"\\nQ5: Interpreting Coefficients in Elastic Net Regression\")\n",
    "print(coefficient_interpretation)\n",
    "\n",
    "print(\"\\nQ6: Handling Missing Values\")\n",
    "print(missing_values_summary)\n",
    "\n",
    "print(\"\\nQ7: Using Elastic Net Regression for Feature Selection\")\n",
    "print(feature_selection_summary)\n",
    "\n",
    "print(\"\\nQ8: Pickling and Unpickling a Trained Model\")\n",
    "print(pickle_usage_summary)\n",
    "\n",
    "print(\"\\nQ9: Purpose of Pickling a Model\")\n",
    "print(pickling_purpose_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

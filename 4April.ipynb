{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c931e-a373-4291-8614-72dfc2b8bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset for demonstration\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a decision tree classifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=data.target_names, columns=data.target_names)\n",
    "\n",
    "# Q1: Decision Tree Classifier\n",
    "decision_tree_explanation = \"\"\"\n",
    "**Decision Tree Classifier**:\n",
    "- **Algorithm**: Decision trees classify data by splitting it into subsets based on feature values. Each split is based on maximizing information gain (or minimizing impurity).\n",
    "- **How It Works**:\n",
    "  1. **Start** at the root node (entire dataset).\n",
    "  2. **Split** the data into subsets based on the feature that results in the highest information gain (or lowest impurity).\n",
    "  3. **Repeat** the process for each subset, creating branches and nodes until a stopping criterion is met (e.g., max depth, minimum samples per leaf).\n",
    "  4. **Predict** class labels by traversing the tree from the root to a leaf node, based on feature values of the input data.\n",
    "\"\"\"\n",
    "\n",
    "# Q2: Mathematical Intuition\n",
    "math_intuition_explanation = \"\"\"\n",
    "**Mathematical Intuition**:\n",
    "1. **Entropy**: Measures the impurity or randomness in the data. For a node with classes, entropy is calculated as:\n",
    "   - Entropy = - Σ (p_i * log2(p_i))\n",
    "   - Where p_i is the probability of class i in the node.\n",
    "\n",
    "2. **Information Gain**: Measures the reduction in entropy after splitting the data on a feature. It is calculated as:\n",
    "   - Information Gain = Entropy(before split) - Σ (weighted entropy(after split))\n",
    "\n",
    "3. **Gini Impurity**: An alternative to entropy, calculated as:\n",
    "   - Gini Impurity = 1 - Σ (p_i^2)\n",
    "   - Where p_i is the proportion of class i in the node.\n",
    "\n",
    "4. **Tree Construction**: The algorithm selects the feature that maximizes information gain (or minimizes Gini impurity) for each split, creating branches until the stopping criteria are met.\n",
    "\"\"\"\n",
    "\n",
    "# Q3: Binary Classification\n",
    "binary_classification_explanation = \"\"\"\n",
    "**Binary Classification with Decision Trees**:\n",
    "- **Process**:\n",
    "  1. **Train** the decision tree on a binary target variable (e.g., 'yes' or 'no').\n",
    "  2. **Split** the data based on the feature that best separates the two classes (e.g., highest information gain).\n",
    "  3. **Continue** splitting until the nodes are pure or meet other stopping criteria.\n",
    "  4. **Predict** the class for new samples by following the splits until reaching a leaf node that provides the class label.\n",
    "\"\"\"\n",
    "\n",
    "# Q4: Geometric Intuition\n",
    "geometric_intuition_explanation = \"\"\"\n",
    "**Geometric Intuition**:\n",
    "- **Concept**: A decision tree partitions the feature space into rectangular regions. Each region corresponds to a class label.\n",
    "- **Visualization**: The tree creates decision boundaries that are parallel to the axes (features). For binary classification, the boundaries can be visualized as lines dividing the feature space into regions where each region is classified into one of the two classes.\n",
    "- **Prediction**: New samples are classified based on the region they fall into.\n",
    "\"\"\"\n",
    "\n",
    "# Q5: Confusion Matrix\n",
    "confusion_matrix_explanation = \"\"\"\n",
    "**Confusion Matrix**:\n",
    "- **Definition**: A table used to evaluate the performance of a classification model by showing the number of correct and incorrect predictions for each class.\n",
    "- **Components**:\n",
    "  - **True Positives (TP)**: Correctly predicted positive cases.\n",
    "  - **True Negatives (TN)**: Correctly predicted negative cases.\n",
    "  - **False Positives (FP)**: Incorrectly predicted positive cases.\n",
    "  - **False Negatives (FN)**: Incorrectly predicted negative cases.\n",
    "- **Usage**: Helps in calculating performance metrics like accuracy, precision, recall, and F1 score.\n",
    "\"\"\"\n",
    "\n",
    "# Q6: Example of Confusion Matrix and Metrics\n",
    "confusion_matrix_example = \"\"\"\n",
    "**Confusion Matrix Example**:\n",
    "- **True Positives (TP)**: 30 (correctly predicted positive cases)\n",
    "- **True Negatives (TN)**: 30 (correctly predicted negative cases)\n",
    "- **False Positives (FP)**: 2 (incorrectly predicted positive cases)\n",
    "- **False Negatives (FN)**: 8 (incorrectly predicted negative cases)\n",
    "\n",
    "**Metrics Calculation**:\n",
    "- **Precision** = TP / (TP + FP) = 30 / (30 + 2) = 0.94\n",
    "- **Recall** = TP / (TP + FN) = 30 / (30 + 8) = 0.79\n",
    "- **F1 Score** = 2 * (Precision * Recall) / (Precision + Recall) = 2 * (0.94 * 0.79) / (0.94 + 0.79) = 0.86\n",
    "\"\"\"\n",
    "\n",
    "# Q7: Choosing Evaluation Metrics\n",
    "evaluation_metric_selection = \"\"\"\n",
    "**Choosing Evaluation Metrics**:\n",
    "- **Considerations**:\n",
    "  - **Class Imbalance**: Metrics like precision, recall, and F1 score are better for imbalanced datasets.\n",
    "  - **Business Goals**: Choose metrics that align with the goals (e.g., precision for fraud detection).\n",
    "  - **Application Context**: Evaluate which metrics best reflect the model's performance in the given context.\n",
    "\"\"\"\n",
    "\n",
    "# Q8: Example of Precision Importance\n",
    "precision_importance_example = \"\"\"\n",
    "**Example of Precision Importance**:\n",
    "- **Scenario**: Email spam detection.\n",
    "- **Reason**: False positives (non-spam emails classified as spam) can lead to missed important emails. High precision ensures that most emails classified as spam are indeed spam.\n",
    "\"\"\"\n",
    "\n",
    "# Q9: Example of Recall Importance\n",
    "recall_importance_example = \"\"\"\n",
    "**Example of Recall Importance**:\n",
    "- **Scenario**: Medical diagnosis for a rare disease.\n",
    "- **Reason**: Missing a positive case (false negatives) can have serious health implications. High recall ensures most patients with the disease are correctly identified.\n",
    "\"\"\"\n",
    "\n",
    "# Display results\n",
    "print(\"Q1: Decision Tree Classifier\")\n",
    "print(decision_tree_explanation)\n",
    "\n",
    "print(\"\\nQ2: Mathematical Intuition\")\n",
    "print(math_intuition_explanation)\n",
    "\n",
    "print(\"\\nQ3: Binary Classification with Decision Trees\")\n",
    "print(binary_classification_explanation)\n",
    "\n",
    "print(\"\\nQ4: Geometric Intuition\")\n",
    "print(geometric_intuition_explanation)\n",
    "\n",
    "print(\"\\nQ5: Confusion Matrix\")\n",
    "print(confusion_matrix_explanation)\n",
    "\n",
    "print(\"\\nQ6: Example of Confusion Matrix and Metrics\")\n",
    "print(confusion_matrix_example)\n",
    "\n",
    "print(\"\\nQ7: Choosing Evaluation Metrics\")\n",
    "print(evaluation_metric_selection)\n",
    "\n",
    "print(\"\\nQ8: Example of Precision Importance\")\n",
    "print(precision_importance_example)\n",
    "\n",
    "print(\"\\nQ9: Example of Recall Importance\")\n",
    "print(recall_importance_example)\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(model, filled=True, feature_names=data.feature_names, class_names=data.target_names)\n",
    "plt.title('Decision Tree Visualization')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

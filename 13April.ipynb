{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1913b9f-c5f6-425e-8a60-8a1f6e80aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load sample data for demonstration\n",
    "data = load_boston()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='PRICE')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print out the performance metric\n",
    "print(f\"Mean Squared Error of the Random Forest Regressor: {mse:.2f}\")\n",
    "\n",
    "# Explanations\n",
    "print(\"\\nQ1. What is Random Forest Regressor?\")\n",
    "print(\"Random Forest Regressor is an ensemble learning method for regression that constructs a multitude of decision trees during training and outputs the mean prediction of the individual trees to improve accuracy and control overfitting.\")\n",
    "\n",
    "print(\"\\nQ2. How does Random Forest Regressor reduce the risk of overfitting?\")\n",
    "print(\"Random Forest Regressor reduces the risk of overfitting by averaging the predictions of multiple decision trees, which helps in generalizing better than a single decision tree. Each tree is trained on a random subset of the data, and the aggregation of trees makes the model less sensitive to individual noise in the training data.\")\n",
    "\n",
    "print(\"\\nQ3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\")\n",
    "print(\"The Random Forest Regressor aggregates the predictions by averaging the outputs of all the decision trees in the forest. Each tree provides a prediction, and the final prediction is the average of these individual predictions.\")\n",
    "\n",
    "print(\"\\nQ4. What are the hyperparameters of Random Forest Regressor?\")\n",
    "print(\"Key hyperparameters of the Random Forest Regressor include:\")\n",
    "print(\"1. `n_estimators`: The number of trees in the forest.\")\n",
    "print(\"2. `max_depth`: The maximum depth of each tree.\")\n",
    "print(\"3. `min_samples_split`: The minimum number of samples required to split an internal node.\")\n",
    "print(\"4. `min_samples_leaf`: The minimum number of samples required to be at a leaf node.\")\n",
    "print(\"5. `max_features`: The number of features to consider when looking for the best split.\")\n",
    "print(\"6. `bootstrap`: Whether bootstrap samples are used when building trees.\")\n",
    "\n",
    "print(\"\\nQ5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\")\n",
    "print(\"A Decision Tree Regressor builds a single decision tree based on the entire dataset, which can be prone to overfitting. In contrast, a Random Forest Regressor builds multiple decision trees on random subsets of the data and averages their predictions, which helps to reduce overfitting and improve generalization.\")\n",
    "\n",
    "print(\"\\nQ6. What are the advantages and disadvantages of Random Forest Regressor?\")\n",
    "print(\"Advantages:\")\n",
    "print(\"1. Handles large datasets with higher dimensionality.\")\n",
    "print(\"2. Reduces overfitting compared to a single decision tree.\")\n",
    "print(\"3. Provides feature importance scores.\")\n",
    "print(\"Disadvantages:\")\n",
    "print(\"1. Computationally intensive, especially with a large number of trees.\")\n",
    "print(\"2. Less interpretable compared to a single decision tree.\")\n",
    "\n",
    "print(\"\\nQ7. What is the output of Random Forest Regressor?\")\n",
    "print(\"The output of a Random Forest Regressor is a continuous numerical value, which is the average of the predictions made by all the individual decision trees in the forest.\")\n",
    "\n",
    "print(\"\\nQ8. Can Random Forest Regressor be used for classification tasks?\")\n",
    "print(\"No, Random Forest Regressor is specifically designed for regression tasks. For classification tasks, you would use Random Forest Classifier, which provides class probabilities and predictions based on the majority vote of individual decision trees.\")\n",
    "\n",
    "# Show the example output\n",
    "print(\"\\nExample Random Forest Regressor Results:\")\n",
    "print(\"Mean Squared Error of the Random Forest Regressor:\", mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
